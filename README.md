# Домашнее задание №1

## Содержание
- [Описание](#описание)
- [Инструкции по настройке](#инструкции-по-настройке)
- [Использование](#использование)
- [Остановка сервисов](#остановка-сервисов)
- [Очистка](#очистка)
- [Примечания](#примечания)
- [Подробнее про взаимодействие producer consumer](#подробнее-про-взаимодействие-producer-consumer)

## Описание
Проект состоит из трех модулей:
- producer
- consumer
- shared-data

Также имеется docker compose, который поднимает кластер kafka (3 брокера c KRaft режимом), а также сервисы producer и consumer для общения с помощью kafka.
**(Конечно, 3 брокера для простой отправки сообщения излишне, но я просто решил попрактиковаться)**
Проект содержит maven wrapper для сборки. 
## Предварительные требования
Для запуска проекта необходимы:
- Docker
- Docker Compose
- Java 21 (для локальной сборки проекта)

## Инструкции по настройке
### 1. Клонируйте репозиторий:
```bash
git clone <url-репозитория>
cd WeatherStation
```
### 2. Соберите модуль shared-data:
```bash
cd shared-data
./mvnw clean install
cd ..
```
Эта команда устанавливает модуль shared-data в локальный Maven-репозиторий, чтобы он был доступен для consumer и producer.
### 3. Соберите модуль consumer:
```bash
cd consumer
./mvnw clean package
cd ..
```
Эта команда создает исполняемый JAR-файл consumer.jar в папке consumer/target.
### 4. Соберите модуль producer:
```bash
cd producer
./mvnw clean package
cd ..
```
Эта команда создает исполняемый JAR-файл producer.jar в папке producer/target.
### 5. Запустите Docker Compose:
```bash
docker-compose up -d
```
Эта команда запускает все сервисы (kafka1, kafka2, kafka3, consumer, producer) в фоновом режиме. Убедитесь, что JAR-файлы собраны перед запуском, так как они используются в Docker-образах.

## Использование
После запуска сервисов вы можете взаимодействовать с продюсером для генерации событий прогнозов погоды:
- Сервис producer доступен на порту 8080.
- Чтобы запустить генерацию прогнозов, отправьте POST-запрос на /weather через curl:
```bash
curl -X POST http://localhost:8080/weather
```
- Или с помощью Postman

Это сгенерирует прогнозы погоды на одну неделю для 20-ти городов России и отправит их в Kafka topic с именем "weather-forecast-topic".
- Сервис consumer слушает topic, логирует получаемые данные, а также по итогам "ускоренной недели" логирует некоторые аналитические данные. 
Вы можете проверить логи либо проверив docker контейнер consumer:
```bash
docker-compose logs -f consumer
```
Или проверить файл consumer.log, который является volume для контейнера и куда также записываются логи (он лежит по пути **root/logs/consumer/consumer.log**)

## Остановка сервисов
Чтобы остановить все запущенные сервисы, выполните:
```bash
docker-compose down
```
Это остановит и удалит все контейнеры, определенные в docker-compose.yml

## Очистка
Для полного удаления данных, включая тома (volumes), используйте:
```bash
docker-compose down -v
```
Это удалит все тома, включая данные Kafka.

## Примечания
- Порты сервисов:
  - Консьюмер: 8081
  - Продюсер: 8080
- Брокеры Kafka:
  - Внешний доступ: порты 9092, 9093, 9094 (для подключения с хост-машины)
  - Внутренний доступ (внутри Docker-сети): kafka1:19092, kafka2:19092, kafka3:19092

## Подробнее про взаимодействие producer consumer
Kafka topic настроен в классе KafkaConfig (на стороне producer):
```java
    @Bean
    public NewTopic weatherForecastTopic() {
        return TopicBuilder.name("weather-forecast-topic")
                .partitions(3)
                .replicas(3)
                .config("min.insync.replicas", "2")
                .build();
    }
```
А также настроена dlt для ошибочных сообщений с такими же параметрами.
- Задано 3 партиции (на стороне consumer стоит надстройка concurrency=3, что позволяет обрабатывать параллельно три партиции). При отправке прогнозов погоды ключом является город, что гарантирует последовательность обработки данных для одного города.
- Задано 3 реплики - обеспечивает отказоустойчивость
- Задано "min.insync.replicas" = 2, что означает - минимальное количество реплик, которые должны быть "в синхронизации" = 2 реплики. Так как всего реплик 3, а подтверждения ждем от всех реплик (acks = all), то значение min.insync.replicas=2 обеспечивает компромисс между устойчивостью и доступностью. Оно гарантирует, что сообщение записывается минимум на 2 реплики, минимизируя риск потери данных при сбое одной ноды, но не требует синхронизации всех 3 (возможное замедление записи из-за сетевых задержек).

